{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-23T21:24:41.995248Z",
     "start_time": "2019-10-23T21:24:41.281020Z"
    }
   },
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-23T21:24:42.014928Z",
     "start_time": "2019-10-23T21:24:42.001244Z"
    }
   },
   "outputs": [],
   "source": [
    "#import data\n",
    "data = pd.read_csv('random.csv',header=None)\n",
    "#random = pd.read_csv('random.csv',header=None)\n",
    "\n",
    "threshold = 0.0001\n",
    "learningrate = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "data =pd.read_excel(\"Book1.xlsx\")\n",
    "threshold = 0.00001\n",
    "learningrate = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-23T21:24:42.027960Z",
     "start_time": "2019-10-23T21:24:42.017936Z"
    }
   },
   "outputs": [],
   "source": [
    "#split data into attributes and labels\n",
    "inputs = data.iloc[:,:-1]\n",
    "inputs.insert(0, 'bias', 1)\n",
    "output=data.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2   -1\n",
       "3    1\n",
       "4    1\n",
       "5   -1\n",
       "6   -1\n",
       "7   -1\n",
       "Name: Unnamed: 3, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-23T21:24:54.747430Z",
     "start_time": "2019-10-23T21:24:42.031923Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result =[]\n",
    "w = np.zeros(inputs.shape[1])\n",
    "w[0] =0.3\n",
    "SSE=10\n",
    "SSEold=200000\n",
    "changeinSSE=1\n",
    "while changeinSSE>threshold:\n",
    "#for i in range(10):\n",
    "    prediction = np.dot(w.T,np.array(inputs).T)\n",
    "    error = np.subtract(np.array(output),prediction)\n",
    "    gradient = np.dot(error,np.array(inputs))\n",
    "    SSE = np.sum(np.square(error)) ##SSEnew\n",
    "    changeinSSE = SSEold-SSE\n",
    "    result.append(np.append(w,SSE))\n",
    "    w = w+learningrate*gradient.T\n",
    "    SSEold=SSE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-23T21:24:54.957233Z",
     "start_time": "2019-10-23T21:24:54.751354Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.720000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.299760</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.000400</td>\n",
       "      <td>8.712451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.299520</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.000800</td>\n",
       "      <td>8.704914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.299281</td>\n",
       "      <td>0.001199</td>\n",
       "      <td>-4.440892e-20</td>\n",
       "      <td>-0.001199</td>\n",
       "      <td>8.697389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.299041</td>\n",
       "      <td>0.001598</td>\n",
       "      <td>-4.440892e-20</td>\n",
       "      <td>-0.001598</td>\n",
       "      <td>8.689876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.298802</td>\n",
       "      <td>0.001997</td>\n",
       "      <td>-4.440892e-20</td>\n",
       "      <td>-0.001997</td>\n",
       "      <td>8.682376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.298563</td>\n",
       "      <td>0.002395</td>\n",
       "      <td>-4.440892e-20</td>\n",
       "      <td>-0.002395</td>\n",
       "      <td>8.674887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.298324</td>\n",
       "      <td>0.002793</td>\n",
       "      <td>-4.440892e-20</td>\n",
       "      <td>-0.002793</td>\n",
       "      <td>8.667410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.298085</td>\n",
       "      <td>0.003191</td>\n",
       "      <td>-4.440892e-20</td>\n",
       "      <td>-0.003191</td>\n",
       "      <td>8.659945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.297847</td>\n",
       "      <td>0.003589</td>\n",
       "      <td>-4.440892e-20</td>\n",
       "      <td>-0.003589</td>\n",
       "      <td>8.652492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.297609</td>\n",
       "      <td>0.003986</td>\n",
       "      <td>-4.440892e-20</td>\n",
       "      <td>-0.003986</td>\n",
       "      <td>8.645051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.297371</td>\n",
       "      <td>0.004382</td>\n",
       "      <td>-8.881784e-20</td>\n",
       "      <td>-0.004382</td>\n",
       "      <td>8.637622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.297133</td>\n",
       "      <td>0.004779</td>\n",
       "      <td>-8.881784e-20</td>\n",
       "      <td>-0.004779</td>\n",
       "      <td>8.630205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.296895</td>\n",
       "      <td>0.005175</td>\n",
       "      <td>-8.881784e-20</td>\n",
       "      <td>-0.005175</td>\n",
       "      <td>8.622800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.296657</td>\n",
       "      <td>0.005571</td>\n",
       "      <td>-8.881784e-20</td>\n",
       "      <td>-0.005571</td>\n",
       "      <td>8.615406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.296420</td>\n",
       "      <td>0.005967</td>\n",
       "      <td>-4.440892e-20</td>\n",
       "      <td>-0.005967</td>\n",
       "      <td>8.608024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.296183</td>\n",
       "      <td>0.006362</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.006362</td>\n",
       "      <td>8.600654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.295946</td>\n",
       "      <td>0.006757</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.006757</td>\n",
       "      <td>8.593296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.295709</td>\n",
       "      <td>0.007151</td>\n",
       "      <td>4.440892e-20</td>\n",
       "      <td>-0.007151</td>\n",
       "      <td>8.585950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.295473</td>\n",
       "      <td>0.007546</td>\n",
       "      <td>4.440892e-20</td>\n",
       "      <td>-0.007546</td>\n",
       "      <td>8.578615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.295236</td>\n",
       "      <td>0.007939</td>\n",
       "      <td>4.440892e-20</td>\n",
       "      <td>-0.007939</td>\n",
       "      <td>8.571293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.295000</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>4.440892e-20</td>\n",
       "      <td>-0.008333</td>\n",
       "      <td>8.563981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.294764</td>\n",
       "      <td>0.008726</td>\n",
       "      <td>4.440892e-20</td>\n",
       "      <td>-0.008726</td>\n",
       "      <td>8.556682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.294528</td>\n",
       "      <td>0.009119</td>\n",
       "      <td>4.440892e-20</td>\n",
       "      <td>-0.009119</td>\n",
       "      <td>8.549394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.294293</td>\n",
       "      <td>0.009512</td>\n",
       "      <td>8.881784e-20</td>\n",
       "      <td>-0.009512</td>\n",
       "      <td>8.542118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.294057</td>\n",
       "      <td>0.009905</td>\n",
       "      <td>8.881784e-20</td>\n",
       "      <td>-0.009905</td>\n",
       "      <td>8.534854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.293822</td>\n",
       "      <td>0.010297</td>\n",
       "      <td>8.881784e-20</td>\n",
       "      <td>-0.010297</td>\n",
       "      <td>8.527601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.293587</td>\n",
       "      <td>0.010688</td>\n",
       "      <td>8.881784e-20</td>\n",
       "      <td>-0.010688</td>\n",
       "      <td>8.520359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.293352</td>\n",
       "      <td>0.011080</td>\n",
       "      <td>8.881784e-20</td>\n",
       "      <td>-0.011080</td>\n",
       "      <td>8.513130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.293117</td>\n",
       "      <td>0.011471</td>\n",
       "      <td>4.440892e-20</td>\n",
       "      <td>-0.011471</td>\n",
       "      <td>8.505912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4112</th>\n",
       "      <td>0.011166</td>\n",
       "      <td>0.481390</td>\n",
       "      <td>1.083336e-34</td>\n",
       "      <td>-0.481390</td>\n",
       "      <td>4.006539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4113</th>\n",
       "      <td>0.011157</td>\n",
       "      <td>0.481405</td>\n",
       "      <td>1.083336e-34</td>\n",
       "      <td>-0.481405</td>\n",
       "      <td>4.006528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4114</th>\n",
       "      <td>0.011148</td>\n",
       "      <td>0.481420</td>\n",
       "      <td>1.083336e-34</td>\n",
       "      <td>-0.481420</td>\n",
       "      <td>4.006518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4115</th>\n",
       "      <td>0.011139</td>\n",
       "      <td>0.481435</td>\n",
       "      <td>1.083336e-34</td>\n",
       "      <td>-0.481435</td>\n",
       "      <td>4.006507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4116</th>\n",
       "      <td>0.011130</td>\n",
       "      <td>0.481450</td>\n",
       "      <td>1.083336e-34</td>\n",
       "      <td>-0.481450</td>\n",
       "      <td>4.006497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4117</th>\n",
       "      <td>0.011121</td>\n",
       "      <td>0.481464</td>\n",
       "      <td>1.083336e-34</td>\n",
       "      <td>-0.481464</td>\n",
       "      <td>4.006487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4118</th>\n",
       "      <td>0.011112</td>\n",
       "      <td>0.481479</td>\n",
       "      <td>4.440892e-20</td>\n",
       "      <td>-0.481479</td>\n",
       "      <td>4.006476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4119</th>\n",
       "      <td>0.011104</td>\n",
       "      <td>0.481494</td>\n",
       "      <td>4.440892e-20</td>\n",
       "      <td>-0.481494</td>\n",
       "      <td>4.006466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4120</th>\n",
       "      <td>0.011095</td>\n",
       "      <td>0.481509</td>\n",
       "      <td>4.440892e-20</td>\n",
       "      <td>-0.481509</td>\n",
       "      <td>4.006455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4121</th>\n",
       "      <td>0.011086</td>\n",
       "      <td>0.481524</td>\n",
       "      <td>4.440892e-20</td>\n",
       "      <td>-0.481524</td>\n",
       "      <td>4.006445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4122</th>\n",
       "      <td>0.011077</td>\n",
       "      <td>0.481538</td>\n",
       "      <td>4.440892e-20</td>\n",
       "      <td>-0.481538</td>\n",
       "      <td>4.006435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4123</th>\n",
       "      <td>0.011068</td>\n",
       "      <td>0.481553</td>\n",
       "      <td>4.440892e-20</td>\n",
       "      <td>-0.481553</td>\n",
       "      <td>4.006425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4124</th>\n",
       "      <td>0.011059</td>\n",
       "      <td>0.481568</td>\n",
       "      <td>4.440892e-20</td>\n",
       "      <td>-0.481568</td>\n",
       "      <td>4.006414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4125</th>\n",
       "      <td>0.011050</td>\n",
       "      <td>0.481583</td>\n",
       "      <td>4.440892e-20</td>\n",
       "      <td>-0.481583</td>\n",
       "      <td>4.006404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4126</th>\n",
       "      <td>0.011042</td>\n",
       "      <td>0.481597</td>\n",
       "      <td>4.440892e-20</td>\n",
       "      <td>-0.481597</td>\n",
       "      <td>4.006394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4127</th>\n",
       "      <td>0.011033</td>\n",
       "      <td>0.481612</td>\n",
       "      <td>4.440892e-20</td>\n",
       "      <td>-0.481612</td>\n",
       "      <td>4.006384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4128</th>\n",
       "      <td>0.011024</td>\n",
       "      <td>0.481627</td>\n",
       "      <td>4.440892e-20</td>\n",
       "      <td>-0.481627</td>\n",
       "      <td>4.006373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4129</th>\n",
       "      <td>0.011015</td>\n",
       "      <td>0.481642</td>\n",
       "      <td>4.440892e-20</td>\n",
       "      <td>-0.481642</td>\n",
       "      <td>4.006363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4130</th>\n",
       "      <td>0.011006</td>\n",
       "      <td>0.481656</td>\n",
       "      <td>4.440892e-20</td>\n",
       "      <td>-0.481656</td>\n",
       "      <td>4.006353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4131</th>\n",
       "      <td>0.010997</td>\n",
       "      <td>0.481671</td>\n",
       "      <td>1.083336e-34</td>\n",
       "      <td>-0.481671</td>\n",
       "      <td>4.006343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4132</th>\n",
       "      <td>0.010989</td>\n",
       "      <td>0.481686</td>\n",
       "      <td>-4.440892e-20</td>\n",
       "      <td>-0.481686</td>\n",
       "      <td>4.006333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4133</th>\n",
       "      <td>0.010980</td>\n",
       "      <td>0.481700</td>\n",
       "      <td>-4.440892e-20</td>\n",
       "      <td>-0.481700</td>\n",
       "      <td>4.006323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4134</th>\n",
       "      <td>0.010971</td>\n",
       "      <td>0.481715</td>\n",
       "      <td>-4.440892e-20</td>\n",
       "      <td>-0.481715</td>\n",
       "      <td>4.006312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4135</th>\n",
       "      <td>0.010962</td>\n",
       "      <td>0.481730</td>\n",
       "      <td>-4.440892e-20</td>\n",
       "      <td>-0.481730</td>\n",
       "      <td>4.006302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4136</th>\n",
       "      <td>0.010953</td>\n",
       "      <td>0.481744</td>\n",
       "      <td>-4.440892e-20</td>\n",
       "      <td>-0.481744</td>\n",
       "      <td>4.006292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4137</th>\n",
       "      <td>0.010945</td>\n",
       "      <td>0.481759</td>\n",
       "      <td>-4.440892e-20</td>\n",
       "      <td>-0.481759</td>\n",
       "      <td>4.006282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4138</th>\n",
       "      <td>0.010936</td>\n",
       "      <td>0.481773</td>\n",
       "      <td>-4.440892e-20</td>\n",
       "      <td>-0.481773</td>\n",
       "      <td>4.006272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4139</th>\n",
       "      <td>0.010927</td>\n",
       "      <td>0.481788</td>\n",
       "      <td>-4.440892e-20</td>\n",
       "      <td>-0.481788</td>\n",
       "      <td>4.006262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4140</th>\n",
       "      <td>0.010918</td>\n",
       "      <td>0.481803</td>\n",
       "      <td>-4.440892e-20</td>\n",
       "      <td>-0.481803</td>\n",
       "      <td>4.006252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4141</th>\n",
       "      <td>0.010910</td>\n",
       "      <td>0.481817</td>\n",
       "      <td>-8.881784e-20</td>\n",
       "      <td>-0.481817</td>\n",
       "      <td>4.006242</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4142 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1             2         3         4\n",
       "0     0.300000  0.000000  0.000000e+00  0.000000  8.720000\n",
       "1     0.299760  0.000400  0.000000e+00 -0.000400  8.712451\n",
       "2     0.299520  0.000800  0.000000e+00 -0.000800  8.704914\n",
       "3     0.299281  0.001199 -4.440892e-20 -0.001199  8.697389\n",
       "4     0.299041  0.001598 -4.440892e-20 -0.001598  8.689876\n",
       "5     0.298802  0.001997 -4.440892e-20 -0.001997  8.682376\n",
       "6     0.298563  0.002395 -4.440892e-20 -0.002395  8.674887\n",
       "7     0.298324  0.002793 -4.440892e-20 -0.002793  8.667410\n",
       "8     0.298085  0.003191 -4.440892e-20 -0.003191  8.659945\n",
       "9     0.297847  0.003589 -4.440892e-20 -0.003589  8.652492\n",
       "10    0.297609  0.003986 -4.440892e-20 -0.003986  8.645051\n",
       "11    0.297371  0.004382 -8.881784e-20 -0.004382  8.637622\n",
       "12    0.297133  0.004779 -8.881784e-20 -0.004779  8.630205\n",
       "13    0.296895  0.005175 -8.881784e-20 -0.005175  8.622800\n",
       "14    0.296657  0.005571 -8.881784e-20 -0.005571  8.615406\n",
       "15    0.296420  0.005967 -4.440892e-20 -0.005967  8.608024\n",
       "16    0.296183  0.006362  0.000000e+00 -0.006362  8.600654\n",
       "17    0.295946  0.006757  0.000000e+00 -0.006757  8.593296\n",
       "18    0.295709  0.007151  4.440892e-20 -0.007151  8.585950\n",
       "19    0.295473  0.007546  4.440892e-20 -0.007546  8.578615\n",
       "20    0.295236  0.007939  4.440892e-20 -0.007939  8.571293\n",
       "21    0.295000  0.008333  4.440892e-20 -0.008333  8.563981\n",
       "22    0.294764  0.008726  4.440892e-20 -0.008726  8.556682\n",
       "23    0.294528  0.009119  4.440892e-20 -0.009119  8.549394\n",
       "24    0.294293  0.009512  8.881784e-20 -0.009512  8.542118\n",
       "25    0.294057  0.009905  8.881784e-20 -0.009905  8.534854\n",
       "26    0.293822  0.010297  8.881784e-20 -0.010297  8.527601\n",
       "27    0.293587  0.010688  8.881784e-20 -0.010688  8.520359\n",
       "28    0.293352  0.011080  8.881784e-20 -0.011080  8.513130\n",
       "29    0.293117  0.011471  4.440892e-20 -0.011471  8.505912\n",
       "...        ...       ...           ...       ...       ...\n",
       "4112  0.011166  0.481390  1.083336e-34 -0.481390  4.006539\n",
       "4113  0.011157  0.481405  1.083336e-34 -0.481405  4.006528\n",
       "4114  0.011148  0.481420  1.083336e-34 -0.481420  4.006518\n",
       "4115  0.011139  0.481435  1.083336e-34 -0.481435  4.006507\n",
       "4116  0.011130  0.481450  1.083336e-34 -0.481450  4.006497\n",
       "4117  0.011121  0.481464  1.083336e-34 -0.481464  4.006487\n",
       "4118  0.011112  0.481479  4.440892e-20 -0.481479  4.006476\n",
       "4119  0.011104  0.481494  4.440892e-20 -0.481494  4.006466\n",
       "4120  0.011095  0.481509  4.440892e-20 -0.481509  4.006455\n",
       "4121  0.011086  0.481524  4.440892e-20 -0.481524  4.006445\n",
       "4122  0.011077  0.481538  4.440892e-20 -0.481538  4.006435\n",
       "4123  0.011068  0.481553  4.440892e-20 -0.481553  4.006425\n",
       "4124  0.011059  0.481568  4.440892e-20 -0.481568  4.006414\n",
       "4125  0.011050  0.481583  4.440892e-20 -0.481583  4.006404\n",
       "4126  0.011042  0.481597  4.440892e-20 -0.481597  4.006394\n",
       "4127  0.011033  0.481612  4.440892e-20 -0.481612  4.006384\n",
       "4128  0.011024  0.481627  4.440892e-20 -0.481627  4.006373\n",
       "4129  0.011015  0.481642  4.440892e-20 -0.481642  4.006363\n",
       "4130  0.011006  0.481656  4.440892e-20 -0.481656  4.006353\n",
       "4131  0.010997  0.481671  1.083336e-34 -0.481671  4.006343\n",
       "4132  0.010989  0.481686 -4.440892e-20 -0.481686  4.006333\n",
       "4133  0.010980  0.481700 -4.440892e-20 -0.481700  4.006323\n",
       "4134  0.010971  0.481715 -4.440892e-20 -0.481715  4.006312\n",
       "4135  0.010962  0.481730 -4.440892e-20 -0.481730  4.006302\n",
       "4136  0.010953  0.481744 -4.440892e-20 -0.481744  4.006292\n",
       "4137  0.010945  0.481759 -4.440892e-20 -0.481759  4.006282\n",
       "4138  0.010936  0.481773 -4.440892e-20 -0.481773  4.006272\n",
       "4139  0.010927  0.481788 -4.440892e-20 -0.481788  4.006262\n",
       "4140  0.010918  0.481803 -4.440892e-20 -0.481803  4.006252\n",
       "4141  0.010910  0.481817 -8.881784e-20 -0.481817  4.006242\n",
       "\n",
       "[4142 rows x 5 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for iteration # 0\n",
      "\n",
      "Input : \n",
      "[[ 1. -1.  1.]\n",
      " [ 1. -1. -1.]\n",
      " [-1.  1.  1.]\n",
      " [-1.  1. -1.]\n",
      " [ 1.  1. -1.]\n",
      " [-1. -1.  1.]\n",
      " [ 1.  1.  1.]\n",
      " [-1. -1. -1.]]\n",
      "Actual Output: \n",
      "[[ 1.]\n",
      " [ 1.]\n",
      " [-1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]]\n",
      "Predicted Output: \n",
      "[[0.69034751]\n",
      " [0.6299119 ]\n",
      " [0.67661834]\n",
      " [0.61499755]\n",
      " [0.68425974]\n",
      " [0.62168242]\n",
      " [0.73276509]\n",
      " [0.56498433]]\n",
      "Loss: \n",
      "1.4216653022333603\n",
      "\n",
      "\n",
      "for iteration # 100\n",
      "\n",
      "Input : \n",
      "[[ 1. -1.  1.]\n",
      " [ 1. -1. -1.]\n",
      " [-1.  1.  1.]\n",
      " [-1.  1. -1.]\n",
      " [ 1.  1. -1.]\n",
      " [-1. -1.  1.]\n",
      " [ 1.  1.  1.]\n",
      " [-1. -1. -1.]]\n",
      "Actual Output: \n",
      "[[ 1.]\n",
      " [ 1.]\n",
      " [-1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]]\n",
      "Predicted Output: \n",
      "[[2.15068662e-06]\n",
      " [9.33716485e-01]\n",
      " [2.14467680e-06]\n",
      " [9.33543088e-01]\n",
      " [9.72166734e-01]\n",
      " [8.64958608e-07]\n",
      " [5.14902233e-03]\n",
      " [5.80333761e-03]]\n",
      "Loss: \n",
      "0.6289439181441375\n",
      "\n",
      "\n",
      "for iteration # 200\n",
      "\n",
      "Input : \n",
      "[[ 1. -1.  1.]\n",
      " [ 1. -1. -1.]\n",
      " [-1.  1.  1.]\n",
      " [-1.  1. -1.]\n",
      " [ 1.  1. -1.]\n",
      " [-1. -1.  1.]\n",
      " [ 1.  1.  1.]\n",
      " [-1. -1. -1.]]\n",
      "Actual Output: \n",
      "[[ 1.]\n",
      " [ 1.]\n",
      " [-1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]]\n",
      "Predicted Output: \n",
      "[[2.85873617e-07]\n",
      " [9.56203695e-01]\n",
      " [2.85577704e-07]\n",
      " [9.56160303e-01]\n",
      " [9.81339548e-01]\n",
      " [1.18560539e-07]\n",
      " [2.36757440e-03]\n",
      " [2.62038301e-03]]\n",
      "Loss: \n",
      "0.6267721088760677\n",
      "\n",
      "\n",
      "for iteration # 300\n",
      "\n",
      "Input : \n",
      "[[ 1. -1.  1.]\n",
      " [ 1. -1. -1.]\n",
      " [-1.  1.  1.]\n",
      " [-1.  1. -1.]\n",
      " [ 1.  1. -1.]\n",
      " [-1. -1.  1.]\n",
      " [ 1.  1.  1.]\n",
      " [-1. -1. -1.]]\n",
      "Actual Output: \n",
      "[[ 1.]\n",
      " [ 1.]\n",
      " [-1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]]\n",
      "Predicted Output: \n",
      "[[9.27527440e-08]\n",
      " [9.65197746e-01]\n",
      " [9.26972694e-08]\n",
      " [9.65177644e-01]\n",
      " [9.84986598e-01]\n",
      " [3.91854362e-08]\n",
      " [1.52798405e-03]\n",
      " [1.67711952e-03]]\n",
      "Loss: \n",
      "0.6261330785532403\n",
      "\n",
      "\n",
      "for iteration # 400\n",
      "\n",
      "Input : \n",
      "[[ 1. -1.  1.]\n",
      " [ 1. -1. -1.]\n",
      " [-1.  1.  1.]\n",
      " [-1.  1. -1.]\n",
      " [ 1.  1. -1.]\n",
      " [-1. -1.  1.]\n",
      " [ 1.  1.  1.]\n",
      " [-1. -1. -1.]]\n",
      "Actual Output: \n",
      "[[ 1.]\n",
      " [ 1.]\n",
      " [-1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]]\n",
      "Predicted Output: \n",
      "[[4.24332142e-08]\n",
      " [9.70321412e-01]\n",
      " [4.24158585e-08]\n",
      " [9.70309629e-01]\n",
      " [9.87069614e-01]\n",
      " [1.81662108e-08]\n",
      " [1.12562532e-03]\n",
      " [1.22908967e-03]]\n",
      "Loss: \n",
      "0.6258302219414733\n",
      "\n",
      "\n",
      "for iteration # 500\n",
      "\n",
      "Input : \n",
      "[[ 1. -1.  1.]\n",
      " [ 1. -1. -1.]\n",
      " [-1.  1.  1.]\n",
      " [-1.  1. -1.]\n",
      " [ 1.  1. -1.]\n",
      " [-1. -1.  1.]\n",
      " [ 1.  1.  1.]\n",
      " [-1. -1. -1.]]\n",
      "Actual Output: \n",
      "[[ 1.]\n",
      " [ 1.]\n",
      " [-1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]]\n",
      "Predicted Output: \n",
      "[[2.33088481e-08]\n",
      " [9.73724691e-01]\n",
      " [2.33017212e-08]\n",
      " [9.73716866e-01]\n",
      " [9.88458878e-01]\n",
      " [1.00824433e-08]\n",
      " [8.90106400e-04]\n",
      " [9.68337960e-04]]\n",
      "Loss: \n",
      "0.62565412891292\n",
      "\n",
      "\n",
      "for iteration # 600\n",
      "\n",
      "Input : \n",
      "[[ 1. -1.  1.]\n",
      " [ 1. -1. -1.]\n",
      " [-1.  1.  1.]\n",
      " [-1.  1. -1.]\n",
      " [ 1.  1. -1.]\n",
      " [-1. -1.  1.]\n",
      " [ 1.  1.  1.]\n",
      " [-1. -1. -1.]]\n",
      "Actual Output: \n",
      "[[ 1.]\n",
      " [ 1.]\n",
      " [-1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]]\n",
      "Predicted Output: \n",
      "[[1.43449751e-08]\n",
      " [9.76191073e-01]\n",
      " [1.43415106e-08]\n",
      " [9.76185458e-01]\n",
      " [9.89470030e-01]\n",
      " [6.25769540e-09]\n",
      " [7.35671435e-04]\n",
      " [7.98067579e-04]]\n",
      "Loss: \n",
      "0.6255391932924018\n",
      "\n",
      "\n",
      "for iteration # 700\n",
      "\n",
      "Input : \n",
      "[[ 1. -1.  1.]\n",
      " [ 1. -1. -1.]\n",
      " [-1.  1.  1.]\n",
      " [-1.  1. -1.]\n",
      " [ 1.  1. -1.]\n",
      " [-1. -1.  1.]\n",
      " [ 1.  1.  1.]\n",
      " [-1. -1. -1.]]\n",
      "Actual Output: \n",
      "[[ 1.]\n",
      " [ 1.]\n",
      " [-1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]]\n",
      "Predicted Output: \n",
      "[[9.53963939e-09]\n",
      " [9.78082165e-01]\n",
      " [9.53775022e-09]\n",
      " [9.78077919e-01]\n",
      " [9.90248572e-01]\n",
      " [4.19128914e-09]\n",
      " [6.26677667e-04]\n",
      " [6.78285445e-04]]\n",
      "Loss: \n",
      "0.6254583558574534\n",
      "\n",
      "\n",
      "for iteration # 800\n",
      "\n",
      "Input : \n",
      "[[ 1. -1.  1.]\n",
      " [ 1. -1. -1.]\n",
      " [-1.  1.  1.]\n",
      " [-1.  1. -1.]\n",
      " [ 1.  1. -1.]\n",
      " [-1. -1.  1.]\n",
      " [ 1.  1.  1.]\n",
      " [-1. -1. -1.]]\n",
      "Actual Output: \n",
      "[[ 1.]\n",
      " [ 1.]\n",
      " [-1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]]\n",
      "Predicted Output: \n",
      "[[6.71081160e-09]\n",
      " [9.79590631e-01]\n",
      " [6.70969198e-09]\n",
      " [9.79587295e-01]\n",
      " [9.90872051e-01]\n",
      " [2.96669741e-09]\n",
      " [5.45680103e-04]\n",
      " [5.89503485e-04]]\n",
      "Loss: \n",
      "0.6253984448348635\n",
      "\n",
      "\n",
      "for iteration # 900\n",
      "\n",
      "Input : \n",
      "[[ 1. -1.  1.]\n",
      " [ 1. -1. -1.]\n",
      " [-1.  1.  1.]\n",
      " [-1.  1. -1.]\n",
      " [ 1.  1. -1.]\n",
      " [-1. -1.  1.]\n",
      " [ 1.  1.  1.]\n",
      " [-1. -1. -1.]]\n",
      "Actual Output: \n",
      "[[ 1.]\n",
      " [ 1.]\n",
      " [-1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]]\n",
      "Predicted Output: \n",
      "[[4.92643139e-09]\n",
      " [9.80829637e-01]\n",
      " [4.92572463e-09]\n",
      " [9.80826939e-01]\n",
      " [9.91386060e-01]\n",
      " [2.18973914e-09]\n",
      " [4.83140377e-04]\n",
      " [5.21103254e-04]]\n",
      "Loss: \n",
      "0.6253522882101687\n",
      "\n",
      "\n",
      "for iteration # 1000\n",
      "\n",
      "Input : \n",
      "[[ 1. -1.  1.]\n",
      " [ 1. -1. -1.]\n",
      " [-1.  1.  1.]\n",
      " [-1.  1. -1.]\n",
      " [ 1.  1. -1.]\n",
      " [-1. -1.  1.]\n",
      " [ 1.  1.  1.]\n",
      " [-1. -1. -1.]]\n",
      "Actual Output: \n",
      "[[ 1.]\n",
      " [ 1.]\n",
      " [-1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]]\n",
      "Predicted Output: \n",
      "[[3.73948949e-09]\n",
      " [9.81870535e-01]\n",
      " [3.73902072e-09]\n",
      " [9.81868303e-01]\n",
      " [9.91819387e-01]\n",
      " [1.67024561e-09]\n",
      " [4.33406415e-04]\n",
      " [4.66810612e-04]]\n",
      "Loss: \n",
      "0.6253156501908222\n",
      "\n",
      "\n",
      "for iteration # 1100\n",
      "\n",
      "Input : \n",
      "[[ 1. -1.  1.]\n",
      " [ 1. -1. -1.]\n",
      " [-1.  1.  1.]\n",
      " [-1.  1. -1.]\n",
      " [ 1.  1. -1.]\n",
      " [-1. -1.  1.]\n",
      " [ 1.  1.  1.]\n",
      " [-1. -1. -1.]]\n",
      "Actual Output: \n",
      "[[ 1.]\n",
      " [ 1.]\n",
      " [-1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]]\n",
      "Predicted Output: \n",
      "[[2.91599762e-09]\n",
      " [9.82760812e-01]\n",
      " [2.91567406e-09]\n",
      " [9.82758932e-01]\n",
      " [9.92191221e-01]\n",
      " [1.30815060e-09]\n",
      " [3.92917552e-04]\n",
      " [4.22682527e-04]]\n",
      "Loss: \n",
      "0.6252858696063216\n",
      "\n",
      "\n",
      "for iteration # 1200\n",
      "\n",
      "Input : \n",
      "[[ 1. -1.  1.]\n",
      " [ 1. -1. -1.]\n",
      " [-1.  1.  1.]\n",
      " [-1.  1. -1.]\n",
      " [ 1.  1. -1.]\n",
      " [-1. -1.  1.]\n",
      " [ 1.  1.  1.]\n",
      " [-1. -1. -1.]]\n",
      "Actual Output: \n",
      "[[ 1.]\n",
      " [ 1.]\n",
      " [-1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]]\n",
      "Predicted Output: \n",
      "[[2.32477663e-09]\n",
      " [9.83533447e-01]\n",
      " [2.32454587e-09]\n",
      " [9.83531839e-01]\n",
      " [9.92514911e-01]\n",
      " [1.04709122e-09]\n",
      " [3.59319785e-04]\n",
      " [3.86117630e-04]]\n",
      "Loss: \n",
      "0.6252611911702474\n",
      "\n",
      "\n",
      "for iteration # 1300\n",
      "\n",
      "Input : \n",
      "[[ 1. -1.  1.]\n",
      " [ 1. -1. -1.]\n",
      " [-1.  1.  1.]\n",
      " [-1.  1. -1.]\n",
      " [ 1.  1. -1.]\n",
      " [-1. -1.  1.]\n",
      " [ 1.  1.  1.]\n",
      " [-1. -1. -1.]]\n",
      "Actual Output: \n",
      "[[ 1.]\n",
      " [ 1.]\n",
      " [-1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]]\n",
      "Predicted Output: \n",
      "[[1.88810364e-09]\n",
      " [9.84212143e-01]\n",
      " [1.88793449e-09]\n",
      " [9.84210750e-01]\n",
      " [9.92800066e-01]\n",
      " [8.53530698e-10]\n",
      " [3.30994912e-04]\n",
      " [3.55330927e-04]]\n",
      "Loss: \n",
      "0.6252404106365141\n",
      "\n",
      "\n",
      "for iteration # 1400\n",
      "\n",
      "Input : \n",
      "[[ 1. -1.  1.]\n",
      " [ 1. -1. -1.]\n",
      " [-1.  1.  1.]\n",
      " [-1.  1. -1.]\n",
      " [ 1.  1. -1.]\n",
      " [-1. -1.  1.]\n",
      " [ 1.  1.  1.]\n",
      " [-1. -1. -1.]]\n",
      "Actual Output: \n",
      "[[ 1.]\n",
      " [ 1.]\n",
      " [-1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]]\n",
      "Predicted Output: \n",
      "[[1.55778202e-09]\n",
      " [9.84814428e-01]\n",
      " [1.55765512e-09]\n",
      " [9.84813210e-01]\n",
      " [9.93053809e-01]\n",
      " [7.06591677e-10]\n",
      " [3.06794079e-04]\n",
      " [3.29057200e-04]]\n",
      "Loss: \n",
      "0.6252226745160129\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import numpy as np \n",
    "      \n",
    "# Each row is a training example, each column is a feature  [X1, X2, X3]\n",
    "X=np.array(([1,-1,1],[1,-1,-1],[-1,1,1],[-1,1,-1],[1,1,-1],[-1,-1,1],[1,1,1],[-1,-1,-1]), dtype=float)\n",
    "y=np.array(([1],[1],[-1],[1],[1],[-1],[-1],[-1]), dtype=float)\n",
    "\n",
    "# Define useful functions    \n",
    "\n",
    "# Activation function\n",
    "def sigmoid(t):\n",
    "    return 1/(1+np.exp(-t))\n",
    "\n",
    "# Derivative of sigmoid\n",
    "def sigmoid_derivative(p):\n",
    "    return p * (1 - p)\n",
    "\n",
    "# Class definition\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, x,y):\n",
    "        self.input = x\n",
    "        self.weights1= np.random.rand(self.input.shape[1],4) # considering we have 4 nodes in the hidden layer\n",
    "        self.weights2 = np.random.rand(4,1)\n",
    "        self.y = y\n",
    "        self.output = np. zeros(y.shape)\n",
    "        \n",
    "    def feedforward(self):\n",
    "        self.layer1 = sigmoid(np.dot(self.input, self.weights1))\n",
    "        self.layer2 = sigmoid(np.dot(self.layer1, self.weights2))\n",
    "        return self.layer2\n",
    "        \n",
    "    def backprop(self):\n",
    "        d_weights2 = np.dot(self.layer1.T, 2*(self.y -self.output)*sigmoid_derivative(self.output))\n",
    "        d_weights1 = np.dot(self.input.T, np.dot(2*(self.y -self.output)*sigmoid_derivative(self.output), self.weights2.T)*sigmoid_derivative(self.layer1))\n",
    "    \n",
    "        self.weights1 += d_weights1\n",
    "        self.weights2 += d_weights2\n",
    "\n",
    "    def train(self, X, y):\n",
    "        self.output = self.feedforward()\n",
    "        self.backprop()\n",
    "        \n",
    "\n",
    "NN = NeuralNetwork(X,y)\n",
    "for i in range(1500): # trains the NN 1,000 times\n",
    "    if i % 100 ==0: \n",
    "        print (\"for iteration # \" + str(i) + \"\\n\")\n",
    "        print (\"Input : \\n\" + str(X))\n",
    "        print (\"Actual Output: \\n\" + str(y))\n",
    "        print (\"Predicted Output: \\n\" + str(NN.feedforward()))\n",
    "        print (\"Loss: \\n\" + str(np.mean(np.square(y - NN.feedforward())))) # mean sum squared loss\n",
    "        print (\"\\n\")\n",
    "  \n",
    "    NN.train(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "X=np.array(([1,0,1],[1,0,0],[0,1,1],[0,1,0],[1,1,0],[0,0,1],[1,1,1],[0,0,0]), dtype=float)\n",
    "y=np.array(([1],[1],[0],[1],[1],[0],[0],[0]), dtype=float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MLPClassifier(activation='identity',hidden_layer_sizes=(1), random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anacoda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:916: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Anacoda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='identity', alpha=0.0001, batch_size='auto',\n",
       "       beta_1=0.9, beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=1, learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=1, shuffle=True, solver='adam', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X, y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.38592986],\n",
       "        [ 0.37654952],\n",
       "        [-1.03099848]]), array([[-1.03588759]])]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.coefs_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
